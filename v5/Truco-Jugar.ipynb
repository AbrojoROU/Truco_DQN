{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from Truco_Core import *\n",
    "from Truco_Value_Network import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para jugar como humano usamos el metodo <b>Play_Human_game()</b> de la clase Motor dentro del paquete Truco_Core\n",
    "\n",
    "Recibe 3 parametros: \n",
    "- player 1 (p1)\n",
    "- player 2 (p2)\n",
    "- modo dios (true/false, nos muestra las cartas y los puntajes que la maquina considera en sus jugadas)\n",
    "\n",
    "\n",
    "El Humano es un tipo de Agente (Clase Humano dentro de Truco_Core)\n",
    "Hay <b>3 tipos de Agente</b> contra los cuales jugar \n",
    "<b>AgenteRandom</b>  (no tiene mucha gracia, actua completamente al azar)\n",
    "<b>AgenteGreedyDVN</b> (toma la mejor accion de las posibles)\n",
    "<b>AgenteSoftmaxDVN</b> (estocastico en su toma de decisiones, probabilidad de accion basada en el puntaje relativo sobre las demas)\n",
    "\n",
    "<b>SoftmaxDVN</b> quizas no siempre tome las mejores decisiones pero es menos predecible y mas dificil de explotar patrones.\n",
    "\n",
    "A los Agentes DVN <b>se les debe cargar una Red DVN</b>, aqui les cargamos por ejemplo la gen20. Tener cuidado ademas de que la DVN sea la de su jugador (no es lo mismo la de p1 que la de p2)\n",
    "\n",
    "<b>ADVERTENCIA:</b> Los modelos de los agentes (archivos h5) deben estar guardados en una subcarpeta con nombre <b>\"value_pickles\"</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_37 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_35 (LeakyReLU)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_36 (LeakyReLU)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_37 (LeakyReLU)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_38 (LeakyReLU)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_39 (LeakyReLU)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_40 (LeakyReLU)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 80,901\n",
      "Trainable params: 80,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_46 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_41 (LeakyReLU)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_42 (LeakyReLU)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_43 (LeakyReLU)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_44 (LeakyReLU)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_45 (LeakyReLU)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_46 (LeakyReLU)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_47 (LeakyReLU)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_48 (LeakyReLU)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 80,901\n",
      "Trainable params: 80,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "### Primero erificamos que los agentes entrenados existen en disco\n",
    "###\n",
    "\n",
    "import keras\n",
    "\n",
    "gen_p1 = \"value_pickles\\gen20_\"\n",
    "p1_DVN = keras.models.load_model(gen_p1 + \"p1_DVN.h5\")\n",
    "p1_DVN.summary()\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "gen_p1 = \"value_pickles\\gen20_\"\n",
    "p1_DVN = keras.models.load_model(gen_p1 + \"p2_DVN.h5\")\n",
    "p1_DVN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######################################\n",
    "\n",
    "\n",
    "\n",
    "<font size=\"+2\"><b>AHORA SI, A JUGAR!</b></font>\n",
    "\n",
    "\n",
    "\n",
    "######################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\MarcosP\\Anaconda3\\envs\\udemy_RL_1\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\MarcosP\\Anaconda3\\envs\\udemy_RL_1\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "\n",
      "  Cartas Jugador 1: [7-Oro, 3-Basto, 11-Espada],  puntos envido: 7\n",
      "  Cartas Jugador 2: [12-Basto, 6-Basto, 5-Espada],  puntos envido: 26\n",
      "\n",
      "###  TE TOCA HUMANO, p1  ###\n",
      "   Truco: NADA_DICHO    Envido: NADA_DICHO\n",
      "   Se jugaron las siguientes cartas: []\n",
      "   Cartas en la mano: [7-Oro, 3-Basto, 11-Espada]\n",
      "\n",
      "Debes elegir accion! acciones posibles: \n",
      "   1. JUGAR_C1\n",
      "   2. JUGAR_C2\n",
      "   3. JUGAR_C3\n",
      "   5. GRITAR\n",
      "   7. ENVIDO\n",
      "   8. REALENVIDO\n",
      "   9. FALTAENVIDO\n",
      "\n",
      "   Ingrese accion: 1\n",
      "   #debug@   p1 - ejecutando accion: Accion.JUGAR_C1   ## EjecutarAccion()   ## T=85.2417s\n",
      "\n",
      " p2 me toca!\n",
      "     @p2 pensando en: ENVIDO,  valor: -1.070\n",
      "     @p2 pensando en: REALENVIDO,  valor: -1.124\n",
      "     @p2 pensando en: FALTAENVIDO,  valor: -2.454\n",
      "     @p2 pensando en: GRITAR,  valor: -1.335\n",
      "     @p2 pensando en: JUGAR_C1,  valor: -1.451\n",
      "     @p2 pensando en: JUGAR_C2,  valor: -1.249\n",
      "     @p2 pensando en: JUGAR_C3,  valor: -1.217\n",
      "     <p2> accion elegida: JUGAR_C2,  valor: -10000\n",
      "  <<p2 - ejecutando accion: Accion.JUGAR_C2>>\n",
      "\n",
      "###  TE TOCA HUMANO, p1  ###\n",
      "   Truco: NADA_DICHO    Envido: NADA_DICHO\n",
      "   Se jugaron las siguientes cartas: [7-Oro, 6-Basto]\n",
      "   Cartas en la mano: [3-Basto, 11-Espada]\n",
      "\n",
      "Debes elegir accion! acciones posibles: \n",
      "   2. JUGAR_C2\n",
      "   3. JUGAR_C3\n",
      "   5. GRITAR\n",
      "\n",
      "   Ingrese accion: 5\n",
      "   #debug@   p1 - ejecutando accion: Accion.GRITAR   ## EjecutarAccion()   ## T=87.2277s\n",
      "\n",
      " p2 me toca!\n",
      "     @p2 pensando en: QUIERO_GRITO,  valor: -1.996\n",
      "     @p2 pensando en: GRITAR,  valor: -2.245\n",
      "     @p2 pensando en: FOLD,  valor: -1.043\n",
      "     <p2> accion elegida: FOLD,  valor: -10000\n",
      "  <<p2 - ejecutando accion: Accion.FOLD>>\n",
      " GANE EL TRUCO! (jugador 1)\n",
      "\n",
      "Termino la partida, cartas jugadas finales: [7-Oro, 6-Basto]\n",
      "Ganó: p1! ,  con puntaje:(1, 0)\n",
      "    >las cartas de p1 eran: [7-Oro, 3-Basto, 11-Espada]\n",
      "    >las cartas de p2 eran: [12-Basto, 6-Basto, 5-Espada]\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "### Ejemplo 1:  HUMANO (p1)  VS  Softmax DVN (p2)\n",
    "###\n",
    "Motor.Play_Human_game(Humano(Reglas.JUGADOR1),\n",
    "                        AgenteSoftmaxDVN(Reglas.JUGADOR2, keras.models.load_model(\"value_pickles\\gen20_p2_DVN.h5\")),\n",
    "                        True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Cartas Jugador 1: [2-Copa, 12-Basto, 12-Oro],  puntos envido: 2\n",
      "  Cartas Jugador 2: [7-Espada, 2-Espada, 1-Copa],  puntos envido: 29\n",
      "\n",
      " p1 me toca!\n",
      "     @p1 pensando en: ENVIDO,  valor: -0.618\n",
      "     @p1 pensando en: REALENVIDO,  valor: -1.800\n",
      "     @p1 pensando en: FALTAENVIDO,  valor: -7.480\n",
      "     @p1 pensando en: GRITAR,  valor: 0.1350\n",
      "     @p1 pensando en: JUGAR_C1,  valor: 0.4665\n",
      "     @p1 pensando en: JUGAR_C2,  valor: 0.4138\n",
      "     @p1 pensando en: JUGAR_C3,  valor: 0.2761\n",
      "     <p1> accion elegida: JUGAR_C1,  valor: [[0.46657956]]\n",
      "  <<p1 - ejecutando accion: Accion.JUGAR_C1>>\n",
      "\n",
      "###  TE TOCA HUMANO, p2  ###\n",
      "   Truco: NADA_DICHO    Envido: NADA_DICHO\n",
      "   Se jugaron las siguientes cartas: [2-Copa]\n",
      "   Cartas en la mano: [7-Espada, 2-Espada, 1-Copa]\n",
      "\n",
      "Debes elegir accion! acciones posibles: \n",
      "   1. JUGAR_C1\n",
      "   2. JUGAR_C2\n",
      "   3. JUGAR_C3\n",
      "   5. GRITAR\n",
      "   7. ENVIDO\n",
      "   8. REALENVIDO\n",
      "   9. FALTAENVIDO\n",
      "\n",
      "   Ingrese accion: 1\n",
      "   #debug@   p2 - ejecutando accion: Accion.JUGAR_C1   ## EjecutarAccion()   ## T=113.822s\n",
      "\n",
      "###  TE TOCA HUMANO, p2  ###\n",
      "   Truco: NADA_DICHO    Envido: NADA_DICHO\n",
      "   Se jugaron las siguientes cartas: [2-Copa, 7-Espada]\n",
      "   Cartas en la mano: [2-Espada, 1-Copa]\n",
      "\n",
      "Debes elegir accion! acciones posibles: \n",
      "   2. JUGAR_C2\n",
      "   3. JUGAR_C3\n",
      "   5. GRITAR\n",
      "\n",
      "   Ingrese accion: 2\n",
      "   #debug@   p2 - ejecutando accion: Accion.JUGAR_C2   ## EjecutarAccion()   ## T=136.697s\n",
      "\n",
      " p1 me toca!\n",
      "     @p1 pensando en: GRITAR,  valor: -1.584\n",
      "     @p1 pensando en: JUGAR_C2,  valor: -1.449\n",
      "     @p1 pensando en: JUGAR_C3,  valor: -1.392\n",
      "     <p1> accion elegida: JUGAR_C3,  valor: [[-1.3927892]]\n",
      "  <<p1 - ejecutando accion: Accion.JUGAR_C3>>\n",
      "\n",
      "###  TE TOCA HUMANO, p2  ###\n",
      "   Truco: NADA_DICHO    Envido: NADA_DICHO\n",
      "   Se jugaron las siguientes cartas: [2-Copa, 7-Espada, 2-Espada, 12-Oro]\n",
      "   Cartas en la mano: [1-Copa]\n",
      "\n",
      "Debes elegir accion! acciones posibles: \n",
      "   3. JUGAR_C3\n",
      "   5. GRITAR\n",
      "\n",
      "   Ingrese accion: 3\n",
      "   #debug@   p2 - ejecutando accion: Accion.JUGAR_C3   ## EjecutarAccion()   ## T=139.695s\n",
      "\n",
      " p1 me toca!\n",
      "     @p1 pensando en: GRITAR,  valor: -2.145\n",
      "     @p1 pensando en: JUGAR_C2,  valor: -1.105\n",
      "     <p1> accion elegida: JUGAR_C2,  valor: [[-1.1051298]]\n",
      "  <<p1 - ejecutando accion: Accion.JUGAR_C2>>\n",
      " GANE EL TRUCO! (jugador 2)\n",
      "\n",
      "Termino la partida, cartas jugadas finales: [2-Copa, 7-Espada, 2-Espada, 12-Oro, 1-Copa, 12-Basto]\n",
      "Ganó: p1! ,  con puntaje:(1, 0)\n",
      "    >las cartas de p1 eran: [2-Copa, 12-Basto, 12-Oro]\n",
      "    >las cartas de p2 eran: [7-Espada, 2-Espada, 1-Copa]\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "### Ejemplo 2:  Greedy DVN (p1)  VS   HUMANO (p2)\n",
    "###\n",
    "Motor.Play_Human_game(AgenteGreedyDVN(Reglas.JUGADOR1,keras.models.load_model(\"value_pickles\\gen20_p1_DVN.h5\")),\n",
    "                            Humano(Reglas.JUGADOR2),\n",
    "                            True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
